{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpSCSxKYJH6b"
      },
      "source": [
        "# Instituto Tecnológico y de Estudios Superiores de Monterrey\n",
        "## Maestría en Inteligencia Artificial Aplicada\n",
        "### Proyecto Integrador (Gpo 10) - TC5035.10\n",
        "\n",
        "### **Proyecto: Diseño Acelerado de Fármacos Agonistas de la Hormona GLP-1**\n",
        "\n",
        "### Avance 2: Ingeniería de características\n",
        "\n",
        "#### **Docentes:**\n",
        "- Dra. Grettel Barceló Alonso - Profesor Titular\n",
        "- Dra. Eduviges Ludivina Facundo Flores  – Profesor Tutor\n",
        "\n",
        "### **Asesores**\n",
        "- Dr. Juan Arturo Nolazco Flores\n",
        "- Dr. Carlos Alberto Brizuela Rodríguez\n",
        "\n",
        "#### **Miembros del equipo:**\n",
        "- Cesar Ivan Herrera Martinez A01796392  \n",
        "- Juan Antonio Cruz Acosta A01795375 \n",
        "- Julio Baltazar Colín A01794476 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ingenieria de características"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introducción: \n",
        "\n",
        "   La ingeniería de características (Feature Engineering) constituye un componente importante en todo proyecto de aprendizaje automático, pues es en esta fase donde los datos crudos adquieren una estructura analítica adecuada para el modelado. En el caso de este proyecto, enfocado en el estudio y modelado de péptidos GLP-1 para el análisis de su comportamiento bioactivo, esta etapa tiene como objetivo transformar las secuencias originales en representaciones numéricas que capturen las propiedades fisicoquímicas más relevantes. A través de este proceso, se busca construir un conjunto de características que refleje las particularidades estructurales y funcionales de cada péptido, sentando las bases para la creación de modelos predictivos más precisos y generalizables.\n",
        "\n",
        "El alcance de este avance se centra específicamente en  “Crear nuevas características para mejorar el rendimiento de los modelos” y  “Mitigar el riesgo de características sesgadas y acelerar la convergencia de algunos algoritmos”, correspondientes a la fase de ingeniería de características. En esta etapa se aplicaran procedimientos sistemáticos de generación, transformación y normalización de variables, mediante el uso de herramientas bioinformáticas como iFeatureOmega para derivar descriptores que describen la composición, hidrofobicidad, carga eléctrica, flexibilidad y otras propiedades moleculares de los péptidos. Estas operaciones permitirán transformar información biológica compleja en vectores numéricos estructurados, que facilitaran la comparación, clasificación y modelado estadístico de las secuencias.\n",
        "\n",
        "Además de la generación de nuevas características, este avance abordará la selección y reducción de variables mediante métodos estadísticos y de extracción de características, con el fin de eliminar redundancias y concentrar la información más significativa del conjunto de datos. Técnicas como el Análisis de Componentes Principales (PCA), el umbral de varianza y la evaluación de correlaciones serán implementadas para identificar las dimensiones más informativas, optimizando así el espacio de representación. Estas estrategias no solo reducen el número de variables necesarias, sino que también contribuyen a la aceleración de la convergencia de los algoritmos de aprendizaje, al simplificar la estructura de los datos y disminuir el ruido estadístico.\n",
        "\n",
        "El propósito integral de este avance es garantizar que el conjunto de datos resultante sea más robusto, balanceado y biológicamente interpretable, minimizando el riesgo de sesgos derivados de la sobre-representación de ciertas propiedades y mejorando la capacidad de los modelos para identificar patrones significativos. De esta forma, la ingeniería de características aplicada en esta etapa no se limitará a un proceso técnico, sino que representará un puente entre el conocimiento biológico y el modelado computacional, asegurando que la información relevante de los péptidos GLP-1 se preserve y se exprese en términos cuantitativos útiles para la fase de aprendizaje automático posterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analisis de secuencias de péptidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analisis de diversidad en las secuencias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Carga de los datos del EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "e:\\Documentos\\Maestria\\Proyecto Integrador\\Codigo\\venv311\\Scripts\\python.exe\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"e:\\Documentos\\Maestria\\Proyecto\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n",
            "\"e:\\Documentos\\Maestria\\Proyecto\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        }
      ],
      "source": [
        "!{sys.executable} -m pip install --upgrade pip\n",
        "!{sys.executable} -m pip install iFeatureOmegaCLI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'iFeatureOmegaCLI'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-3-50462fcc6499>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Análisis de propiedades fisicoquímicas de las secuencias después de CD-HIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0miFeatureOmegaCLI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'iFeatureOmegaCLI'"
          ]
        }
      ],
      "source": [
        "# Carga de archivos y librerias\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "from Bio import SeqIO\n",
        "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Análisis de propiedades fisicoquímicas de las secuencias después de CD-HIT\n",
        "from iFeatureOmega import iFeatureOmegaCLI\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rutas locales a Bibliotecas y utilerias\n",
        "# from pathlib import Path\n",
        "\n",
        "# ruta del directorio del notebook actual\n",
        "notebook_dir = Path.cwd()\n",
        "\n",
        "# Subir un nivel para llegar a la carpeta raíz del proyecto\n",
        "project_root = notebook_dir.parent\n",
        "\n",
        "# Añadir la carpeta raíz al path de Python\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.append(str(project_root))\n",
        "    print(f\"Ruta del proyecto añadida al path: {project_root}\")\n",
        "\n",
        "from src.bio_utils import save_df_as_fasta, fasta_to_dataframe, inspect_fasta_file, calculate_identity_matrix\n",
        "from src.plotting import identity_heatmap, cumulative_variance_plot, plot_pca_2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ruta los archivos de datos\n",
        "directorio_base = Path(\"../\")\n",
        "directorio_datos = Path(directorio_base / \"data\")\n",
        "raw_data_dir = directorio_datos / \"raw\"\n",
        "processed_data_dir = directorio_datos / \"processed\"\n",
        "ruta_125_ec50= directorio_datos/raw_data_dir/ \"125_EC50.csv\"\n",
        "\n",
        "# Ruta archivos procesados\n",
        "\n",
        "# Ruta archivo FASTA filtrado\n",
        "ruta_fasta_glp1_sec_activa= processed_data_dir / \"GLP-1_Activo.fasta\"\n",
        "\n",
        "# Ruta archivo CSV con péptidos GLP-1 identificados\n",
        "ruta_csv_glp_identificados= processed_data_dir / \"glucagon_like_peptides.csv\"\n",
        "\n",
        "# Ruta archivo CSV con péptidos  con actividad EC50\n",
        "ruta_125_ec50= directorio_datos/raw_data_dir/ \"125_EC50.csv\"\n",
        "\n",
        "# Ruta archivo FASTA con péptidos  con actividad EC50\n",
        "ruta_fasta_125_ec50= processed_data_dir / \"125_EC50.fasta\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carga de datos fasta de la proteina GLP-1R\n",
        "load_gpl1_fasta_results = inspect_fasta_file(ruta_fasta_glp1_sec_activa)\n",
        "\n",
        "if load_gpl1_fasta_results and load_gpl1_fasta_results['is_valid']:\n",
        "    print(f\"'{ruta_fasta_glp1_sec_activa}' es válido.\")\n",
        "    print(f\"Se encontraron {load_gpl1_fasta_results['record_count']} registros válidos.\")\n",
        "\n",
        "df_glp1_sec_activa = fasta_to_dataframe(ruta_fasta_glp1_sec_activa)\n",
        "print(f\"Dimensiones del DataFrame: {df_glp1_sec_activa.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# muestra de los datos\n",
        "df_glp1_sec_activa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# carga de datos csv de los peptidos GLP-1 identificados y con actividad EC50\n",
        "try:\n",
        "    df_glp1_identificados = pd.read_csv(ruta_csv_glp_identificados)\n",
        "    df_glp1_identificados.set_index('ID', inplace=True)\n",
        "    print(f\"Archivo '{ruta_csv_glp_identificados}' cargado correctamente.\")\n",
        "    print(f\"Dimensiones del DataFrame: {df_glp1_identificados.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: El archivo '{ruta_csv_glp_identificados}' no se encontró.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_glp1_identificados.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# carga de datos csv de los peptidos con actividad EC50 para entrenar el modelo\n",
        "try:\n",
        "    df_125_ec50 = pd.read_csv(ruta_125_ec50)\n",
        "    df_125_ec50.set_index('Number',inplace=True)\n",
        "    print(f\"Archivo '{ruta_125_ec50}' cargado correctamente.\")\n",
        "    print(f\"Dimensiones del DataFrame: {df_125_ec50.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: El archivo '{ruta_125_ec50}' no se encontró.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Muestra de los datos\n",
        "df_125_ec50.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#conversión de archivos de 125 peptidos a fasta para el calculo de propiedades\n",
        "\n",
        "dt_temp = df_125_ec50.copy()\n",
        "dt_temp['Fasta_Header'] = df_125_ec50['Fasta_Header'] = df_125_ec50['pep_ID'] + ' ' +'EC50_T2'+ ' '+ df_125_ec50['EC50_T2'].astype(str)\n",
        "\n",
        "save_df_as_fasta(\n",
        "    dataframe=dt_temp,\n",
        "    id_col='Fasta_Header',\n",
        "    seq_col='sequence',\n",
        "    output_file=ruta_fasta_125_ec50\n",
        "    \n",
        ")\n",
        "\n",
        "results = inspect_fasta_file(Path(ruta_fasta_125_ec50))\n",
        "\n",
        "if results and results['is_valid']:\n",
        "    print(f\"'{ruta_fasta_125_ec50}' es válido.\")\n",
        "    print(f\"Se encontraron {results['record_count']} registros válidos.\")\n",
        "else:\n",
        "    print(f\"\\nLa validación falló para '{ruta_fasta_125_ec50}'. Por favor, revisa los registros.\")\n",
        "\n",
        "del dt_temp, results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agrupación de secuencias biológicas CD-Hit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CD-HIT\n",
        "\"CD-Hit es una herramienta bioinformática ampliamente utilizada para agrupar secuencias biológicas, como proteínas o ácidos nucleicos, en función de su similitud. Su objetivo principal es reducir la redundancia en grandes conjuntos de datos de secuencias, facilitando el análisis y la interpretación de la información genética o proteica.\n",
        "\n",
        "Utiliza un algoritmo de clustering rápido y eficiente que agrupa secuencias similares basándose en un umbral de identidad definido por el usuario. Las secuencias que superan este umbral se agrupan en un solo clúster, representado por una secuencia representativa, mientras que las secuencias que no cumplen con el criterio permanecen como secuencias individuales.  \n",
        "\n",
        "CD-Hit,Permite identificar familias de secuencias relacionadas, estudiar la diversidad genética, y optimizar bases de datos de secuencias para análisis posteriores, como la anotación funcional o la predicción estructural. CD-Hit es especialmente útil en estudios de genómica, proteómica y metagenómica, donde se manejan grandes volúmenes de datos secuenciales\" (Fu et al., 2012).\n",
        "\n",
        "#### Aplicación al conjunto de datos:\n",
        "\n",
        "En los conjuntos de datos biológicos, es común encontrar secuencias redundantes o con una similitud muy alta (por ejemplo, múltiples entradas para la misma proteína o variantes con mutaciones menores). Esta redundancia, si no se trata, puede introducir un sesgo significativo en los modelos de machine learning. \n",
        "\n",
        "En este análisis, la aplicación de CD-HIT sobre nuestro conjunto de datos de péptidos análogos al glucagón tiene los siguientes objetivos:\n",
        "\n",
        "- Eliminar Redundancia: Se descartan las secuencias idénticas o casi idénticas, que no aportan nueva información al modelo.\n",
        "\n",
        "- Aumentar la Diversidad: Al quedarnos con una única secuencia representativa de cada clúster, nos aseguramos de que el conjunto de datos final contenga una variedad más amplia de péptidos.\n",
        "\n",
        "- Crear un Conjunto de Datos óptimo: Se genera un conjunto de datos \"limpio\" y no sesgado, ideal para el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ruta archivo fasta con resultados de CD-HIT\n",
        "cd_hit_results_fasta = processed_data_dir / \"cd-hit_results.fasta\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Conversión de rutas de Windows a WSL\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "def convert_to_wsl_path(windows_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Convierte una ruta de Windows a su equivalente en WSL usando 'wslpath'.\n",
        "    \n",
        "    Args:\n",
        "        windows_path (str): La ruta en formato Windows (e.g., \"C:\\\\Users\\\\...\").\n",
        "\n",
        "    Returns:\n",
        "        str: La ruta en formato WSL (e.g., \"/mnt/c/Users/...\").\n",
        "    \"\"\"\n",
        "    # Ejecuta 'wslpath -u' para convertir la ruta\n",
        "    result = subprocess.run([\"wsl\", \"wslpath\", \"-u\", windows_path], capture_output=True, text=True, check=True)\n",
        "    # .strip() elimina cualquier espacio o nueva línea al final\n",
        "    return result.stdout.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejecutar CD-HIT en WSL con rutas convertidas\n",
        "#  Define tus rutas en Windows usando pathlib\n",
        "#    .resolve() las convierte en rutas absolutas, lo cual es útil para evitar problemas con rutas relativas\n",
        "input_fasta_win = Path(ruta_fasta_glp1_sec_activa).resolve()\n",
        "output_cdhit_win = Path(cd_hit_results_fasta).resolve()\n",
        "\n",
        "try:\n",
        "    # 2. Convierte las rutas de Windows a formato WSL\n",
        "    input_fasta_wsl = convert_to_wsl_path(str(input_fasta_win))\n",
        "    output_cdhit_wsl = convert_to_wsl_path(str(output_cdhit_win))\n",
        "\n",
        "    print(f\"Ruta de Windows (entrada): {input_fasta_win}\")\n",
        "    print(f\"Ruta de WSL (entrada):    {input_fasta_wsl}\")\n",
        "    print(\"-\" * 20)\n",
        "    print(f\"Ruta de Windows (salida): {output_cdhit_win}\")\n",
        "    print(f\"Ruta de WSL (salida):     {output_cdhit_wsl}\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "    # 3. Construye el comando final con las rutas ya convertidas\n",
        "    command = [\n",
        "        \"wsl\", \n",
        "        \"cd-hit\", \n",
        "        \"-i\", input_fasta_wsl, \n",
        "        \"-o\", output_cdhit_wsl, \n",
        "        \"-c\", \"0.99\",\n",
        "        \"-T\", \"4\"  # Usa 4 hilos (ajusta según tu CPU)\n",
        "    ]\n",
        "\n",
        "    # 4. Ejecuta el comando\n",
        "    print(\"Ejecutando comando en WSL...\")\n",
        "    return_status = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "    # Imprime la salida y los errores para depuración\n",
        "    print(return_status.stdout)\n",
        "    \n",
        "    if return_status.returncode == 0:\n",
        "        print(\"\\nComando ejecutado exitosamente.\")\n",
        "    else:\n",
        "        print(f\"\\nEl comando falló con código de error: {return_status.returncode}\")\n",
        "        print(\"\\n--- ERRORES (STDERR) ---\")\n",
        "        print(return_status.stderr)\n",
        "        \n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Asegúrate de que WSL y/o 'cd-hit' estén instalados y en el PATH del sistema.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error al convertir una ruta con wslpath: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocurrió un error inesperado: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# carga de datos fasta del resultado de cd-hit\n",
        "load_cdhit_fasta_results = inspect_fasta_file(cd_hit_results_fasta)\n",
        "\n",
        "if load_cdhit_fasta_results and load_cdhit_fasta_results['is_valid']:\n",
        "    print(f\"'{cd_hit_results_fasta}' es válido.\")\n",
        "    print(f\"Se encontraron {load_cdhit_fasta_results['record_count']} registros válidos.\")\n",
        "\n",
        "df_cdhit = fasta_to_dataframe(cd_hit_results_fasta)\n",
        "print(f\"Dimensiones del DataFrame: {df_cdhit.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análisis de diversidad de las secuencias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Análisis previo a CD-HIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mapa de calor de la matriz de identidad antes de CD-HIT\n",
        "# 1. Extraer la lista de secuencias\n",
        "sequences_before = df_glp1_sec_activa['sequence'].tolist()\n",
        "\n",
        "# 2. Calcular la matriz\n",
        "print(\"Calculando matriz de identidad ANTES de CD-HIT...\")\n",
        "identity_matrix_before = calculate_identity_matrix(sequences_before)\n",
        "\n",
        "# 3. Visualizar el mapa de calor\n",
        "identity_heatmap(identity_matrix_before, 'Diversidad de Secuencias ANTES de la Reducción')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gráfico 1: Diversidad ANTES de la Reducción \n",
        "Este primer gráfico revela las características del conjunto de datos original:\n",
        "\n",
        "- Alta Redundancia: El mapa está dominado por colores cálidos (verde y amarillo). Esto indica que, en general, las secuencias en el conjunto de datos son muy similares entre sí.\n",
        "\n",
        "- Bloques de Identidad: Se observan grandes cuadrados de color amarillo fuera de la diagonal principal. Estos bloques evidencia de redundancia. Cada bloque representa un grupo de secuencias que son idénticas entre sí.\n",
        "\n",
        "- Sesgo: Un conjunto de datos con esta estructura habría causado un sesgo en un modelo de machine learning. El modelo habría aprendido a reconocer muy bien las características de los grupos sobrerrepresentados, pero tendría un bajo rendimiento para predecir secuencias más diversas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "bat"
        }
      },
      "source": [
        "### Análisis despues de CD-HIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mapa de calor de la matriz de identidad después de CD-HIT\n",
        "# 1. Extraer la lista de secuencias\n",
        "sequences_after = df_cdhit['sequence'].tolist()\n",
        "\n",
        "# 2. Calcular la matriz\n",
        "print(\"Calculando matriz de identidad DESPUÉS de CD-HIT...\")\n",
        "identity_matrix_after = calculate_identity_matrix(sequences_after)\n",
        "\n",
        "# 3. Visualizar el mapa de calor\n",
        "identity_heatmap(identity_matrix_after, 'Diversidad de Secuencias DESPUÉS de la Reducción')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gráfico 2: Diversidad DESPUÉS de la Reducción\n",
        "El segundo gráfico muestra el conjunto de datos después de aplicar CD-HIT:\n",
        "\n",
        "- Reducción del Tamaño del Conjunto de Datos: El número de secuencias se ha reducido de aproximadamente 889 a 224.\n",
        "\n",
        "- Aumento de la Diversidad: El mapa ahora está dominado por el color púrpura oscuro. Esto significa que la similitud entre la mayoría de los pares de secuencias es baja. Las secuencias que quedan son, en su mayoría, distintas entre sí.\n",
        "\n",
        "- Eliminación de la Redundancia: Los grandes bloques amarillos han desaparecido. El color amarillo ahora está en la diagonal principal, donde cada secuencia se compara consigo misma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cálculo de descriptores de Composición y Orden en Secuencias de Proteínas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Descriptores de Composición y Orden en Secuencias de Proteínas\n",
        "Estos métodos transforman secuencias de aminoácidos en vectores numéricos, capturando la información esencial sobre la composición, orden y propiedades fisicoquímicas para su uso en modelos de aprendizaje automático y otras herramientas de analisis de proteinas.\n",
        "\n",
        "Para este análisis e ingenieria de características se eligieron siete propiedades, para mantener limitada la dimensionalidad de el conjunto de datos.\n",
        "\n",
        "#### Descriptores Basados en Composición\n",
        "Estos descriptores se centran en la frecuencia de los aminoácidos o sus agrupaciones.\n",
        "\n",
        "- **AAC (Amino Acid Composition)**: Es el descriptor más fundamental. Calcula la frecuencia relativa de cada uno de los 20 aminoácidos estándar en una secuencia, resultando en un vector de 20 dimensiones. Ignora el orden de los aminoácidos.\n",
        "\n",
        "\n",
        "- **DPC type 1 (Dipeptide Composition)**: Este método calcula la frecuencia de los 400 pares de aminoácidos adyacentes posibles (dipéptidos). Al considerar los vecinos inmediatos, captura información sobre el orden local en la secuencia.\n",
        "\n",
        "\n",
        "#### Descriptores CTD (Composition, Transition, Distribution)\n",
        "\n",
        "- **CTD** convierte la secuencia de aminoácidos en una secuencia de propiedades fisicoquímicas (como hidrofobicidad, polaridad, carga, etc.). Los aminoácidos se clasifican en tres grupos para cada propiedad (ej., para hidrofobicidad: polares, neutros e hidrofóbicos). Este calculo se realiza bajo tres propiedades:\n",
        "\n",
        "- **CTDC** (Composition): Mide la composición global de cada uno de los tres grupos de propiedades en la secuencia. Por ejemplo, para la hidrofobicidad, el resultado sería el porcentaje de residuos polares, neutros e hidrofóbicos. Su fórmula es: \n",
        "\n",
        "$$\n",
        "C(r)=N(r)/N.\n",
        "$$\n",
        "\n",
        "- **CTDT (Transition)**: Describe la frecuencia con la que ocurren transiciones entre los diferentes grupos de propiedades. Por ejemplo, mide qué tan a menudo un residuo polar es seguido por uno neutro, o viceversa. Se calcula como:\n",
        "\n",
        "$$\n",
        "T(r,s) = \\frac{N(r,s) + N(s,r)}{N-1}\n",
        "$$\n",
        "\n",
        "- **CTDD (Distribution)**: Proporciona información sobre la distribución de cada grupo de propiedades a lo largo de la secuencia. Para cada grupo, se calcula la posición del primer residuo, y las posiciones donde se alcanza el 25%, 50%, 75% y 100% de los residuos de ese grupo. Esto da como resultado un vector de 5 dimensiones para cada uno de los 3 grupos.\n",
        "\n",
        "#### Descriptores Basados en el Orden y Propiedades Fisicoquímicas\n",
        "\n",
        "Estos descriptores emplean el orden de la secuencia y las propiedades de los aminoácidos para crear representaciones.\n",
        "\n",
        "- **SOCNumber (Sequence-Order-Coupling Number)**: Este descriptor cuantifica el acoplamiento entre aminoácidos a diferentes distancias. El número de acoplamiento de orden \n",
        "\n",
        "*d* se define como la suma de los cuadrados de las distancias (según matrices de distancia fisicoquímicas como las de Schneider-Wrede o Grantham) entre todos los pares de aminoácidos separados por *d-1* residuos.\n",
        "\n",
        "- **QSOrder (Quasi-sequence-order)**: Los descriptores de cuasi-orden de secuencia combinan la composición de aminoácidos (AAC) con los números de acoplamiento de orden de secuencia (SOCNumber). El vector resultante contiene 20 componentes que representan la frecuencia normalizada de cada aminoácido y componentes adicionales que representan los números de acoplamiento ponderados, capturando así tanto la composición como las correlaciones de orden a largo alcance.\n",
        "\n",
        "- **PAAC (Pseudo-Amino Acid Composition)**: Al igual que QSOrder, el PAAC combina la composición de aminoácidos con información de orden de secuencia. La información de orden se deriva de funciones de correlación basadas en propiedades fisicoquímicas como la hidrofobicidad, hidrofilicidad y masa de la cadena lateral. El resultado es un vector de \n",
        "\n",
        "20+λ dimensiones, donde λ es el número de tiers de correlación considerados.\n",
        "\n",
        "- **APAAC (Amphiphilic Pseudo-Amino Acid Composition)**: Es una variante del PAAC que se enfoca específicamente en las propiedades anfipáticas de la secuencia. Utiliza funciones de correlación basadas en los valores de hidrofobicidad e hidrofilicidad para construir los componentes de orden de secuencia. El vector resultante tiene \n",
        "\n",
        "20+2λ dimensiones, capturando las correlaciones de estas dos propiedades a lo largo de λ tiers.\n",
        "\n",
        "(Chou, 2001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cálculo de las propiedades usando iFeature Omega"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Definímos funciones auxiliares para calcular los descriptores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cargar las configuraciónes\n",
        "ifeatures_settings_json = Path(directorio_datos / \"iFeature Settings\" / \"Protein_parameters_setting.json\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funcion para el cálculo de descriptor\n",
        "\n",
        "def compute_single_descriptor(input_fasta_file, descriptor, settings_json_file=None):\n",
        "    \"\"\"\n",
        "    Calcula un descriptor con iFeatureOmega y devuelve un DataFrame indexado por ID.\n",
        "\n",
        "    Parámetros\n",
        "    ----------\n",
        "    input_fasta_file : str\n",
        "        Ruta al archivo FASTA o TXT con secuencias.\n",
        "    descriptor : str\n",
        "        Nombre del descriptor (por ejemplo, \"AAC\", \"DPC\", \"CTDC\").\n",
        "    settings_json_file : str | None\n",
        "        Ruta al archivo JSON de configuración de parámetros.\n",
        "\n",
        "    Retorna\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        DataFrame con las secuencias como índice y columnas prefijadas con el descriptor.\n",
        "    \"\"\"\n",
        "    print(f\"Calculando descriptor: {descriptor}\")\n",
        "\n",
        "    protein = iFeatureOmegaCLI.iProtein(input_fasta_file)\n",
        "\n",
        "    if settings_json_file:\n",
        "        try:\n",
        "            protein.import_parameters(settings_json_file)\n",
        "        except Exception as e:\n",
        "            print(f\"No se pudo importar parámetros: {e}\")\n",
        "\n",
        "    try:\n",
        "        protein.get_descriptor(descriptor)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al calcular {descriptor}: {e}\")\n",
        "        return None\n",
        "\n",
        "    df = protein.encodings.reset_index()\n",
        "\n",
        "    if df.empty:\n",
        "         print(f\"Descriptor {descriptor} no generó resultados.\")\n",
        "         return None\n",
        "\n",
        "    # # Normalizar el nombre de la columna ID y ponerla como índice\n",
        "    df.rename(columns={df.columns[0]: \"ID\"}, inplace=True)\n",
        "    df = df.set_index(\"ID\")\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funcion para el calculo de varios descriptores usando una lista\n",
        "def compute_peptide_features(input_fasta_file, descriptors, settings_json_file, output_csv=None):\n",
        "    \"\"\"\n",
        "    Calcula descriptores relevantes con iFeatureOmega y devuelve un DataFrame.\n",
        "    \"\"\"\n",
        "    if not descriptors or not isinstance(descriptors, (list, tuple)):\n",
        "        raise ValueError(\"Se necesita una lista no vacía de descriptores.\")\n",
        "\n",
        "    results = []\n",
        "    for desc in descriptors:\n",
        "        df = compute_single_descriptor(input_fasta_file, desc, settings_json_file)\n",
        "        if df is not None:\n",
        "            results.append((desc, df))\n",
        "\n",
        "    if not results:\n",
        "        raise Exception(\"No se pudieron calcular descriptores válidos.\")\n",
        "\n",
        "    combined = results[0][1]\n",
        "    for desc, df in results[1:]:\n",
        "        combined = combined.merge(df, left_index=True, right_index=True, how=\"inner\")\n",
        "\n",
        "    combined.reset_index(inplace=True)\n",
        "\n",
        "    if output_csv:\n",
        "        combined.to_csv(output_csv, index=False)\n",
        "        print(f\"Resultados guardados en {output_csv}\")\n",
        "\n",
        "    expected_ids = results[0][1].index\n",
        "    for desc, df in results[1:]:\n",
        "        lost = set(expected_ids) - set(df.index)\n",
        "        if lost:\n",
        "            print(f\"En el descriptor {desc} faltaron {len(lost)} secuencias: {list(lost)[:3]}...\")\n",
        "\n",
        "    return combined\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definimos una lista de descriptores\n",
        "descriptores = [\n",
        "            \"AAC\",\t\t\t\t# Amino acid composition\n",
        "            \"CKSAAGP type 1\",\t# Composition of k-spaced amino acid group pairs type 1- normalized\n",
        "            \"DPC type 1\",\t\t# Dipeptide composition type 1 - normalized\n",
        "            \"CTDC\",\t\t\t\t# Composition\n",
        "            \"CTDT\",\t\t\t\t# Transition\n",
        "            \"CTDD\",\t\t\t\t# Distribution\n",
        "            \"CTriad\",\t\t\t# Conjoint triad\n",
        "            \"GAAC\",\t\t\t\t# Grouped amino acid composition\n",
        "            \"Moran\",\t\t\t# Moran\n",
        "            \"SOCNumber\",\t\t# Sequence-order-coupling number\n",
        "            \"QSOrder\",\t\t\t# Quasi-sequence-order descriptors\n",
        "            \"PAAC\",\t\t\t\t# Pseudo-amino acid composition\n",
        "            \"APAAC\",\t\t\t# Amphiphilic PAAC\n",
        "            \"NMBroto\",\t\t\t# Auto-cross covariance\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cálculo de los descriptores para las secuencias procedentes de CD-Hit\n",
        "\n",
        "Este conjunto de datos será el que se evaluará para determinar su efectividad para enlazarse al receptor GLP-1R\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculamos los descriptores\n",
        "df_descriptores_cdhit = compute_peptide_features(cd_hit_results_fasta, descriptores, ifeatures_settings_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# muestra de los descriptores\n",
        "df_descriptores_cdhit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Calculamos los descriptores del conjunto de 125 péptidos con actividad EC50 conocida.\n",
        "Este conjunto de datos servirá para entrenar y validad los modelos que se emplearan para predecir la actividad de los péptidos de los que desconocemos su actividad EC50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### calculamos las propiedades fisico quimicas para el conjunto de 125 Peptidos con actividad EC50\n",
        "\n",
        "df_descriptores_125p = compute_peptide_features(ruta_fasta_125_ec50, descriptores, ifeatures_settings_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# muestra de los resultados\n",
        "df_descriptores_125p.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Guardamos la información en formato CSV para el análisis y posterior carga"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unión de los dataframes de las propiedades con los datos de identificación \n",
        "df_resultado = pd.merge(\n",
        "    left=df_descriptores_125p,         \n",
        "    right=df_125_ec50[['pep_ID','sequence' ,'EC50_T2', 'EC50_LOG_T2']], \n",
        "    left_on='ID',                      \n",
        "    right_on='pep_ID',                 \n",
        "    how='left'                        \n",
        ")\n",
        "\n",
        "df_descriptores_125p = df_resultado.drop('pep_ID', axis=1)\n",
        "df_descriptores_125p['ID'] = df_descriptores_125p['ID'].astype(\"string\")\n",
        "df_descriptores_125p['EC50_T2'] = df_descriptores_125p['EC50_T2'].astype(\"float64\")\n",
        "df_descriptores_125p['EC50_LOG_T2'] = df_descriptores_125p['EC50_LOG_T2'].astype(\"float64\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_descriptores_125p.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unión de los dataframes de las propiedades con los datos de identificación \n",
        "df_resultado_desconocidos = pd.merge(\n",
        "    left=df_descriptores_cdhit,         \n",
        "    right=df_glp1_sec_activa[['id','sequence']], \n",
        "    left_on='ID',                      \n",
        "    right_on='id',                 \n",
        "    how='inner'                        \n",
        ")\n",
        "\n",
        "df_descriptores_cdhit = df_resultado_desconocidos.drop('id', axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_descriptores_cdhit.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definición de las rutas de los archivos \n",
        "descriptores_125_csv = processed_data_dir/\"descriptores_125.csv\"\n",
        "descriptores_cdhit_csv = processed_data_dir/\"descriptores_cdhit.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardado de resultados\n",
        "\n",
        "df_descriptores_125p.to_csv(descriptores_125_csv, index=False)   \n",
        "df_descriptores_cdhit.to_csv(descriptores_cdhit_csv, index=False)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analisis de Componentes Principales PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El Análisis de Componentes Principales (PCA,) es una técnica de reducción de dimensionalidad utilizada en ciencia de datos y aprendizaje automático. Su objetivo principal es transformar un conjunto de datos con un gran número de características correlacionadas en un nuevo conjunto de variables no correlacionadas llamadas componentes principales Shlens, J. (2014)\n",
        "\n",
        "El análisis busca las direcciones en los datos donde la varianza es máxima.\n",
        "-\tEl primer componente principal (PC1) es la dirección que captura la mayor cantidad de varianza en los datos.\n",
        "-\tEl segundo componente principal (PC2) es la siguiente dirección que captura la mayor varianza posible, con la condición de ser ortogonal (no estar correlacionado) al PC1.\n",
        "-\tEste proceso continúa hasta que se han calculado todos los componentes posibles.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Escalamiento de Datos \n",
        "\n",
        "PCA es muy sensible a la escala de las variables. Si una característica tiene un rango de valores mucho mayor que otras (por ejemplo, una va de 0 a 1000 y otra de 0 a 1), la primera dominará el cálculo de la varianza y, por lo tanto, los componentes principales. Para evitar esto, es un paso obligatorio estandarizar los datos antes de aplicar PCA. Usamos StandardScaler para transformar cada característica de modo que tenga una media de 0 y una desviación estándar de 1, asegurando que todas contribuyan de manera equitativa al análisis.\n",
        "\n",
        "Se empleó la estandarización con el escalado estandar, debido a que los descriptores presentan magnitudes heterogéneas y el PCA requiere variables centradas y escaladas para reflejar correctamente la varianza relativa.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bibliotecas para PCA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separación de los dato de la columna objetivo y el identificador\n",
        "features = df_descriptores_125p.drop(columns=['ID', 'EC50_T2','sequence'])\n",
        "target = df_descriptores_125p['EC50_T2']\n",
        "ids = df_descriptores_125p['ID']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aplicación de el escalado de características\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculamos PCA con solo dos componentes para visualizar\n",
        "\n",
        "Reduciremos la dimensionalidad de nuestros descriptores de péptidos a solo dos componentes principales (PC1 y PC2). Esto nos permitirá graficar los datos en un diagrama de dispersión 2D. El objetivo es observar visualmente si existen agrupaciones (clusters) o patrones que puedan separar los péptidos según su actividad biológica (EC50_T2) Jolliffe, I. T. (2002)..\n",
        "\n",
        "- PC1 (Primera Componente Principal)\n",
        "\tEs la dirección (vector) en el espacio de variables originales que explica la mayor varianza posible en los datos.\n",
        "\tSe obtiene como una combinación lineal de las variables originales (los descriptores) con ciertos pesos (o loadings).\n",
        "\tEs decir:\n",
        "$$\n",
        "\"PC1\"=a_1 X_1+a_2 X_2+a_3 X_3+⋯+a_n X_n   \n",
        "$$\n",
        "- donde a_ison los coeficientes que maximizan la varianza total.\n",
        "\n",
        "- PC2 (Segunda Componente Principal)\n",
        "\tEs ortogonal (independiente) de PC1.\n",
        "\tExplica la siguiente mayor cantidad de varianza posible en los datos, sin repetir la información de PC1.\n",
        "\tTambién se obtiene como combinación lineal de los descriptores, pero con otros coeficientes b_i:\n",
        "\n",
        "$$\n",
        "\"PC2\"=b_1 X_1+b_2 X_2+b_3 X_3+⋯+b_n X_n\n",
        "$$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cálculo de PCA en conjunto con actividad EC 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cálculo de PCA en conjunto con actividad EC 50\n",
        "pca = PCA(n_components=2)\n",
        "principal_components = pca.fit_transform(features_scaled)\n",
        "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
        "final_df = pd.concat([pca_df, target], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#muestra de datos\n",
        "final_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot\n",
        "plot_pca_2d(final_df, color_by=final_df['EC50_T2'],label = \"EC_50\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Análisis e Interpretación de los Componentes Principales\n",
        "\n",
        "![AnalsisPCA](Pictures/ClustersPCA.jpg)\n",
        "\n",
        "\n",
        "El gráfico de PCA revela cinco zonas distintas que correlacionan las características fisicoquímicas de los péptidos (capturadas por PC1 y PC2) con su potencia biológica (EC₅₀).\n",
        "\n",
        "- **Zona 1 (Péptidos Potentes)**: Ubicada en la esquina inferior izquierda, agrupa péptidos con EC₅₀ baja (<5,000). Sus valores negativos en PC1 y PC2 sugieren alta hidrofobicidad, carga favorable y una composición rica en residuos apolares, lo que resulta en una alta afinidad por el receptor GLP-1.\n",
        "\n",
        "- **Zona 2 (Potencia Media)**: En el centro-izquierda, esta zona contiene péptidos con EC₅₀ intermedia (10,000–20,000). Representa una transición donde un balance entre residuos polares y apolares resulta en una actividad moderada.\n",
        "\n",
        "- **Zona 3 (Potencia Moderada a Baja)**: Situada en la región central, agrupa péptidos con EC₅₀ entre 15,000 y 25,000. Se caracterizan por menor hidrofobicidad y mayor flexibilidad estructural, lo que limita su afinidad por el receptor. La dispersión en esta zona sugiere una alta variabilidad estructural.\n",
        "\n",
        "- **Zona 4 (Familia Estructural)**: En la parte superior, esta zona muestra un clúster de péptidos con alta similitud interna y EC₅₀ de 5,000 a 15,000. Los altos valores de PC2 indican una secuencia ordenada y motivos conservados, representando un buen equilibrio entre estabilidad y actividad.\n",
        "\n",
        "- **Zona 5 (Péptidos Menos Potentes)**: En el extremo derecho, agrupa los péptidos con EC₅₀ alta (>25,000). Sus altos valores de PC1 se asocian con mayor polaridad y menor estabilidad, lo que dificulta una interacción eficaz con el receptor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.plotting import plot_pca_3d\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "pca3d = PCA(n_components=3)\n",
        "principal_components3D = pca3d.fit_transform(features_scaled)\n",
        "pca3d_df = pd.DataFrame(data=principal_components3D, columns=['PC1', 'PC2', 'PC3'])\n",
        "final3d_df = pd.concat([pca3d_df, target], axis=1)\n",
        "\n",
        "# Crear figura con dos subplots horizontales\n",
        "fig = plt.figure(figsize=(13, 5))\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "ax1.set_title('PCA 3D con Datos Conocidos')\n",
        "\n",
        "plot_pca_3d(\n",
        "    final3d_df,\n",
        "    pc_x='PC1',\n",
        "    pc_y='PC2',\n",
        "    pc_z='PC3',\n",
        "    color_by='EC50_T2',\n",
        "    label='Predicción',\n",
        "    xlim=(-25, 30),\n",
        "    ylim=(-25, 30),\n",
        "    zlim=(-25, 30),\n",
        "    ax=ax1,\n",
        ")\n",
        "\n",
        "# Mostrar ambos\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cálculo de PCA con los datos obtenidos de CD-HIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separación de los dato de la columna objetivo y el identificador\n",
        "features = df_descriptores_cdhit.drop(columns=['ID', 'sequence'])\n",
        "\n",
        "# Aplicación de el escalado de características\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principal_components = pca.fit_transform(features_scaled)\n",
        "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
        "final_df = pd.concat([pca_df, target], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#muestra de datos\n",
        "final_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#plot\n",
        "plot_pca_2d(final_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Análisis PCA del Conjunto de Péptidos con Actividad Desconocida\n",
        "\n",
        "\n",
        "![imagenPCAPeptidos2](Pictures/FigPCApeptidos.png)\n",
        "\n",
        "En el análisis de componentes principales (PCA) realizado sobre el conjunto de péptidos con actividad EC₅₀ desconocida, se observan tres zonas bien delimitadas. Al comparar su distribución con la del gráfico anterior, se pueden inferir las siguientes conclusiones:\n",
        "\n",
        "- Zona Izquierda: Los péptidos agrupados en esta región muestran una alta similitud con los de la Zona 2 del análisis previo. Esta correspondencia sugiere que podrían tener una actividad biológica favorable sobre el receptor GLP-1R.\n",
        "\n",
        "- Zonas Central y Derecha: Los péptidos ubicados en las dos zonas restantes se distribuyen en una posición intermedia, análoga a la transición entre las Zonas 2 y 3 del análisis anterior. Debido a esta localización, se predice que su actividad biológica podría ser de moderada a baja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Interpretación de componentes principales (PC1, PC2)\n",
        "Es posible identificar que propiedades son mas importantes para determinar las características de los peptidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interpretación de componentes principales (PC1, PC2)\n",
        "pca_result = pca \n",
        "\n",
        "# Crear un DataFrame con los \"loadings\" o pesos de cada descriptor\n",
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,\n",
        "    columns=['PC1', 'PC2'],\n",
        "    index= features.columns\n",
        ")\n",
        "\n",
        "# Calcular la contribución absoluta total de cada descriptor\n",
        "loadings['|PC1|'] = loadings['PC1'].abs()\n",
        "loadings['|PC2|'] = loadings['PC2'].abs()\n",
        "\n",
        "# Mostrar los 10 descriptores con mayor influencia en cada componente\n",
        "print(\"Principales contribuyentes a PC1:\")\n",
        "display(loadings.sort_values('|PC1|', ascending=False).head(10))\n",
        "\n",
        "print(\"Principales contribuyentes a PC2:\")\n",
        "display(loadings.sort_values('|PC2|', ascending=False).head(10))\n",
        "\n",
        "# graficar la contribución visualmente\n",
        "\n",
        "top_features = loadings.abs().sum(axis=1).sort_values(ascending=False).head(15)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.barh(top_features.index, top_features.values)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(\"Descriptores con mayor contribución global (PC1 + PC2)\")\n",
        "plt.xlabel(\"Carga absoluta combinada\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al analizar los descriptores más influyentes se distingen patrones claros y biológicamente relevantes:\n",
        "\n",
        "- La Hidrofobicidad y la Polaridad son Clave: La propiedad más recurrente en la lista es, por mucho, la hidrofobicidad, seguida de la polaridad. Descriptores como CTDC_hydrophobicity, CTDD_hydrophobicity y CTDC_polarity dominan los primeros puestos. Esto indica que la principal fuente de variación entre los péptidos es su afinidad por el agua. Biológicamente, esto es crucial, ya que la hidrofobicidad dicta cómo se pliega un péptido, su estabilidad y cómo interactúa con el receptor GLP-1, que está en un entorno de membrana celular.\n",
        "\n",
        "- La Composición y Distribución (CTD) Importan: La fuerte presencia de descriptores de la familia CTD (CTDC, CTDD, CTDT) sugiere que no solo importa qué propiedades tienen los péptidos, sino también en qué proporción (Composición) y en qué parte de la secuencia se localizan (Distribución). Por ejemplo, CTDD_hydrophobicity...residue25 y ...residue50 señalan que la hidrofobicidad en el primer cuarto y en la mitad de la secuencia son factores particularmente distintivos.\n",
        "\n",
        "- El Orden de la Secuencia y Residuos Específicos son Relevantes: La aparición de descriptores PAAC, APAAC y QSOrder confirma que el orden secuencial de los aminoácidos es un factor determinante. Estos métodos capturan correlaciones entre residuos a lo largo de la cadena. Notablemente, varios de los descriptores más importantes están asociados con aminoácidos específicos:\n",
        "\n",
        "- Glutamina (Q): Aparece en APAAC_Pc1.Q, PAAC_Xc1.Q y QSOrder...Xr.Q.\n",
        "\n",
        "- Serina (S): Presente en APAAC_Pc1.S y PAAC_Xc1.S.\n",
        "\n",
        "- Dipéptido Histidina-Alanina (HA): Destaca en DPC_HA.\n",
        "\n",
        "\n",
        "En conjunto, los descriptores de tipo DPC (Pairs de aminoácidos) capturan interacciones locales entre residuos adyacentes o cercanos, revelando los patrones de carga y polaridad que gobiernan la afinidad con el receptor GLP-1r. Por su parte, los CTD (Composition, Transition, Distribution) y CTDD aportan información sobre la organización global de propiedades como la hidrofobicidad y la carga, que son esenciales para mantener la estabilidad conformacional y definir las regiones activas de unión. Por último, los PAAC y SOCNumber integran dependencias de largo alcance, permitiendo representar la arquitectura tridimensional del péptido más allá de la composición lineal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cálculo de la varianza acumulada\n",
        "\n",
        "Aunque una visualización en 2D es útil, se pierde información si se entrena un modelo solo con 2 componentes. Por ello, también calcularemos la varianza acumulada explicada, para determinar el número de componentes que capturan mas de 90% de las características.\n",
        "\n",
        " Este gráfico muestra qué porcentaje de la información total de los datos originales es capturado por un número determinado de componentes. Esto es importante para decidir cuántos componentes principales necesitaríamos para entrenar un modelo futuro sin perder una cantidad significativa de información."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculo de PCA con todos los componentes\n",
        "# Se deja PCA() vacío para que calcule todos los componentes posibles\n",
        "pca = PCA()\n",
        "pca.fit(features_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular la varianza acumulada\n",
        "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "cumulative_variance_plot(cumulative_variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Interpretación del Gráfico de Varianza Acumulada \n",
        "\n",
        "La curva azul muestra que Los primeros componentes principales son los más importantes, ya que capturan la mayor parte de la varianza. La curva crece muy rápidamente al principio.\n",
        "A medida que añadimos más componentes, la ganancia de información adicional es cada vez menor, lo que se refleja en que la curva se va aplanando.\n",
        "\n",
        "- Umbral del 90% (Línea Verde): Para retener el 90% de la varianza total de los datos originales, necesitaríamos aproximadamente 78 componentes principales. Esto implica que podemos reducir la dimensionalidad de nuestro conjunto de datos de 224 a solo 78 características y aun así conservar la gran mayoría de la información relevante.\n",
        "\n",
        "- Umbral del 95% (Línea Roja): Si deseamos retener el 95% de la varianza, el número de componentes necesarios aumenta a aproximadamente 100. Para ganar ese 5% adicional de información, necesitamos incluir 22 componentes más."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusiones del Análisis\n",
        "Este análisis se realizó la ingeniería de características, fundamental para transformar las secuencias de péptidos en un conjunto de datos estructurado y de alta calidad, listo para un modelado predictivo.\n",
        "Las principales conclusiones son:\n",
        "1.\tGeneración de Descriptores: Se generó un conjunto  de descriptores fisicoquímicos (AAC, DPC, CTD, PAAC, QSOrder) que capturan las propiedades biológicas de los péptidos, como son la hidrofobicidad y la carga, traduciendo la información biológica a un formato numérico analizable.\n",
        "\n",
        "2.\tReducción de Redundancia Validada: La aplicación de CD-HIT eliminó la redundancia en el conjunto de datos, como se demostró en los mapas de calor. Esto para evitar el sesgo y mejorar la capacidad de generalización de los modelos de machine learning de la entrega siguiente.\n",
        "\n",
        "3.\tDimensionalidad de PCA: El análisis de componentes principales (PCA) mostro que es posible reducir significativamente la dimensionalidad del espacio de características. Con aproximadamente 100 componentes se logra retener el 95% de la información original, si se requiere reducir mas la dimensionalidad se puede usar un conjunto de 68 características que modelan el 90% del comportamiento.\n",
        "\n",
        "4.\tInterpretación Biológica Coherente: El PCA reveló que la variación en los datos está impulsada por propiedades biológicamente relevantes. Los componentes principales se asociaron claramente con la hidrofobicidad, el orden secuencial y la flexibilidad, validando la conexión entre las características extraídas y la actividad biológica de los péptidos.\n",
        "\n",
        "5.\tValidación de Clústeres por Actividad: La visualización del plano PCA nos permitió agrupar los péptidos en clústeres o zonas bien definidas. Se puede apreciar una fuerte correlación entre la posición de estos clústeres y la actividad biológica (EC₅₀), con grupos de péptidos de alta, media y baja potencia. Esto nos permite inferir que grupos de péptidos pueden tener mayor actividad sobre le receptor GLP-1R.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Referencias\n",
        "\n",
        "Chou, K. (2001). Prediction of protein cellular attributes using pseudo‐amino acid composition. Proteins Structure Function And Bioinformatics, 43(3), 246-255. https://doi.org/10.1002/prot.1035\n",
        "\n",
        "\n",
        "- Jolliffe, I. T. (2002). Principal Component Analysis (2nd ed.). Springer.\n",
        "\n",
        "- Shlens, J. (2014). A tutorial on principal component analysis. ArXiv. https://doi.org/10.48550/arXiv.1404.1100\n",
        "\n",
        "- Home. (n.d.). https://sites.google.com/view/cd-hit\n",
        "\n",
        "- Fu, L., Niu, B., Zhu, Z., Wu, S., & Li, W. (2012). CD-HIT: accelerated for clustering the next-generation sequencing data. Bioinformatics, 28(23), 3150-3152. https://doi.org/10.1093/bioinformatics/bts565"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
